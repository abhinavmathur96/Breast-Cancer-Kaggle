{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre v Post Pruning Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graphlab import SFrame, cross_validation\n",
    "import pickle as pkl\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup base node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class node(object):\n",
    "    def __init__(self, isLeaf, splitting_feature, split_value, data,\n",
    "                 leftChild = None, rightChild = None):\n",
    "        self.isLeaf = isLeaf\n",
    "        self.splitting_feature = splitting_feature\n",
    "        self.split_value = split_value\n",
    "        self.leftChild = leftChild\n",
    "        self.rightChild = rightChild\n",
    "        self.data = data\n",
    "    \n",
    "    def gain(self):\n",
    "        data_left = self.data[self.data[self.splitting_feature]\\\n",
    "                                < self.split_value]\n",
    "        data_right = self.data[self.data[self.splitting_feature]\\\n",
    "                                >= self.split_value]\n",
    "        entropy_left_split = (len(data_left) / float(len(self.data)))\\\n",
    "                                * entropy(data_left)\n",
    "        entropy_right_split = (len(data_right) / float(len(self.data)))\\\n",
    "                                * entropy(data_right)\n",
    "        return entropy(self.data) - entropy_left_split - entropy_right_split\n",
    "    \n",
    "    def split_info(self):\n",
    "        data_left = len(self.data[self.data[self.splitting_feature]\\\n",
    "                                < self.split_value])\n",
    "        data_right = len(self.data[self.data[self.splitting_feature]\\\n",
    "                                >= self.split_value])\n",
    "        ratio_left = data_left / float(len(self.data))\n",
    "        ratio_right = data_right / float(len(self.data))\n",
    "        log_left = np.log2(ratio_left)\n",
    "        log_right = np.log2(ratio_right)\n",
    "        if log_left == -np.inf:\n",
    "            log_left = 0.0\n",
    "        if log_right == -np.inf:\n",
    "            log_right == 0.0\n",
    "        return - (ratio_left * log_left + ratio_right * log_right)\n",
    "    \n",
    "    def gain_ratio(self):\n",
    "        return self.gain() / self.split_info()\n",
    "    \n",
    "    def prediction(self):\n",
    "        if (self.data['diagnosis'] == 'M').sum() >\\\n",
    "            (self.data['diagnosis'] == 'B').sum():\n",
    "            return 'M'\n",
    "        else:\n",
    "            return 'B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Entropy and Best Split Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    '''\n",
    "    Calculate Entropy of the given data\n",
    "    '''\n",
    "    if len(data) != 0:\n",
    "        total_data = len(data)\n",
    "        m_freq = (data['diagnosis'] == 'M').sum() / float(total_data)\n",
    "        b_freq = (data['diagnosis'] == 'B').sum() / float(total_data)\n",
    "        if m_freq == 0:\n",
    "            log2_m = 0.0\n",
    "        else:\n",
    "            log2_m = np.log2(m_freq)\n",
    "        if b_freq == 0:\n",
    "            log2_b = 0.0\n",
    "        else:\n",
    "            log2_b = np.log2(b_freq)\n",
    "        return -(m_freq * log2_m + b_freq * log2_b)\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "def best_splitting_feature_gain(data, features, isContinuous=True,\n",
    "                                annotate=False):\n",
    "    '''\n",
    "    Calculate best splitting feature through Entropy\n",
    "    '''\n",
    "    n = float((data['diagnosis'] == 'M').sum())\n",
    "    p = float((data['diagnosis'] == 'B').sum())\n",
    "    entropy_data = entropy(data)\n",
    "    if annotate:\n",
    "        print \"Entropy of data: %f\" % entropy_data\n",
    "\n",
    "    best_feature = None\n",
    "    best_gain = -np.inf\n",
    "\n",
    "    for feature in features:\n",
    "        if annotate:\n",
    "            print 'Working on ' + feature\n",
    "        if isContinuous:\n",
    "            data_sorted = data[feature].sort()\n",
    "            data_points = [np.mean([data_sorted[i], data_sorted[i + 1]]) \\\n",
    "                            for i in range(len(data_sorted) - 1)]\n",
    "            gain = []\n",
    "            for i in data_points:\n",
    "                #For points <= split\n",
    "                pi_tmp = float(((data['diagnosis'] == 'B') & (data[feature] <= i)).sum())\n",
    "                ni_tmp = float(((data['diagnosis'] == 'M') & (data[feature] <= i)).sum())\n",
    "                left_split = float((pi_tmp + ni_tmp) / (p + n))\n",
    "                log_left = np.log2(left_split)\n",
    "                if log_left == -np.inf:\n",
    "                    log_left = 0.0\n",
    "                left_split_info = float(left_split * log_left)\n",
    "                gain.append(((pi_tmp + ni_tmp) / (p + n)) * entropy(data[data[feature] <= i]))\n",
    "\n",
    "                #For points > split\n",
    "                pi_tmp = float(((data['diagnosis'] == 'B') & (data[feature] > i)).sum())\n",
    "                ni_tmp = float(((data['diagnosis'] == 'M') & (data[feature] > i)).sum())\n",
    "                right_split = float((pi_tmp + ni_tmp) / (p + n))\n",
    "                log_right = np.log2(right_split)\n",
    "                if log_right == -np.inf:\n",
    "                    log_right = 0.0\n",
    "                right_split_info = float(right_split * log_right)\n",
    "                gain.append(((pi_tmp + ni_tmp) / (p + n)) * entropy(data[data[feature] > i]))\n",
    "\n",
    "            gain_split = entropy_data - float(sum(gain))\n",
    "            gain_ratio = gain_split / (-(left_split_info + right_split_info))\n",
    "            if annotate:\n",
    "                print 'Gain Ratio from %s: %f' % (feature, gain_ratio)\n",
    "            if gain_ratio > best_gain:\n",
    "                best_gain = gain_ratio\n",
    "                best_feature = feature\n",
    "        else:\n",
    "            print 'TODO: Implement discrete valued Information Gain'\n",
    "\n",
    "    return best_feature, np.median(data[best_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking mistakes by minority class (also used for checking pure nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    '''\n",
    "    Counts basic error in current split based on minority class\n",
    "    '''\n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "\n",
    "    # Count the number of B's (benign tumors)\n",
    "    num_b = (labels_in_node == 'B').sum()\n",
    "\n",
    "    # Count the number of M's (malignant tumors)\n",
    "    num_m = (labels_in_node == 'M').sum()\n",
    "\n",
    "    # Return the number of mistakes that the majority classifier makes.\n",
    "    return min(num_b, num_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create pre-pruned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pre_pruned(data, features, current_depth=0, max_depth=10,\n",
    "                        threshold=10):\n",
    "    '''\n",
    "    Create a decision tree with pre-pruning similar to ID3 or C4.5\n",
    "    '''\n",
    "    target_values = data['diagnosis']\n",
    "    print \"--------------------------------------------------------------------\"\n",
    "    print \"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values))\n",
    "    \n",
    "    # Stopping Condition 1\n",
    "    # Stop at pure nodes\n",
    "    if intermediate_node_num_mistakes(data['diagnosis']) == 0:\n",
    "        print 'Pure node reached'\n",
    "        return node(isLeaf = True, splitting_feature = None,\n",
    "                        split_value = None, data = data)\n",
    "    \n",
    "    # Stopping Condition 2\n",
    "    # Stop when number of datapoints fall below a threshold\n",
    "    if len(data) <= threshold:\n",
    "        print 'Less than %d datapoints left' % threshold\n",
    "        return node(isLeaf = True, splitting_feature = None,\n",
    "                        split_value = None, data = data)\n",
    "    \n",
    "    # Stopping Condition 3\n",
    "    # Stop after specified tree depth\n",
    "    if current_depth >= max_depth:\n",
    "        print 'Max depth reached (%d)' % max_depth\n",
    "        return node(isLeaf = True, splitting_feature = None,\n",
    "                        split_value = None, data = data)\n",
    "    \n",
    "    # Finding best split through gain ratio\n",
    "    splitting_feature, split_value = best_splitting_feature_gain(data, features, 'diagnosis')\n",
    "    left_split = data[data[splitting_feature] < split_value]\n",
    "    right_split = data[data[splitting_feature] >= split_value]\n",
    "    print 'Split on feature %s at %f' % (splitting_feature, split_value)\n",
    "\n",
    "    # Create a leaf node if split is perfect\n",
    "    if len(right_split) == 0:\n",
    "        print 'Creating leaf node for left data'\n",
    "        return node(isLeaf = True, splitting_feature = None,\n",
    "                        split_value = None, data = left_split)\n",
    "    if len(left_split) == 0:\n",
    "        print 'Creating leaf node for right data'\n",
    "        return node(isLeaf = True, splitting_feature = None,\n",
    "                        split_value = None, data = right_split)\n",
    "    \n",
    "    # Recurse on left and right subtrees\n",
    "    left_tree = create_pre_pruned(left_split, features, current_depth+1, max_depth)\n",
    "    right_tree = create_pre_pruned(right_split, features, current_depth+1, max_depth)\n",
    "\n",
    "    return node (\n",
    "        isLeaf = False,\n",
    "        splitting_feature = splitting_feature,\n",
    "        split_value = split_value,\n",
    "        leftChild = left_tree,\n",
    "        rightChild = right_tree,\n",
    "        data = data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create unbounded tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_unbounded(data, features, current_depth=0):\n",
    "    '''\n",
    "    Create a decison tree without any checks.\n",
    "    It is inadvisable to use this without prune().\n",
    "    '''\n",
    "    target_values = data['diagnosis']\n",
    "    print \"--------------------------------------------------------------------\"\n",
    "    print \"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values))\n",
    "\n",
    "    # Stop at pure nodes\n",
    "    if intermediate_node_num_mistakes(data['diagnosis']) == 0:\n",
    "        print 'Pure node reached'\n",
    "        return node(isLeaf = True, splitting_feature = None,\n",
    "                        split_value = None, data = data)\n",
    "    \n",
    "    # Finding best split through gain ratio\n",
    "    splitting_feature, split_value = best_splitting_feature_gain(data, features, 'diagnosis')\n",
    "    left_split = data[data[splitting_feature] < split_value]\n",
    "    right_split = data[data[splitting_feature] >= split_value]\n",
    "    print 'Split on feature %s at %f' % (splitting_feature, split_value)\n",
    "\n",
    "    # Create a leaf node if split is perfect\n",
    "    if len(left_split) == len(data):\n",
    "        print 'Creating leaf node'\n",
    "        return node(isLeaf = True, splitting_feature = None,\n",
    "                        split_value = None, data = left_split)\n",
    "    if len(right_split) == len(data):\n",
    "        print 'Creating leaf node'\n",
    "        return node(isLeaf = True, splitting_feature = None,\n",
    "                        split_value = None, data = right_split)\n",
    "    \n",
    "    # Recurse on left and right subtrees\n",
    "    left_tree = create_unbounded(left_split, features, current_depth+1)\n",
    "    right_tree = create_unbounded(right_split, features, current_depth+1)\n",
    "\n",
    "    return node (\n",
    "        isLeaf = False,\n",
    "        splitting_feature = splitting_feature,\n",
    "        split_value = split_value,\n",
    "        leftChild = left_tree,\n",
    "        rightChild = right_tree,\n",
    "        data = data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to post-prune unbounded tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prune(tree, test_data):\n",
    "    '''\n",
    "    Prunes a pre-built tree. Returns pruned tree and least error encountered.\n",
    "    '''\n",
    "    bfs = [tree]\n",
    "    bfs_iter = 0\n",
    "\n",
    "    while(True):\n",
    "        if bfs_iter == len(bfs):\n",
    "            break\n",
    "        if bfs[bfs_iter].leftChild != None:\n",
    "            bfs.append(bfs[bfs_iter].leftChild)\n",
    "        if bfs[bfs_iter].rightChild != None:\n",
    "            bfs.append(bfs[bfs_iter].rightChild)\n",
    "        bfs_iter += 1\n",
    "    \n",
    "    least_error = evaluate_classification_error(tree, test_data)\n",
    "    snips = 0\n",
    "\n",
    "    bfs.reverse()\n",
    "    for i in bfs:\n",
    "        if i != None:\n",
    "            i.isLeaf = True\n",
    "            error_partial = evaluate_classification_error(tree, test_data)\n",
    "            if error_partial <= least_error:\n",
    "                least_error = error_partial\n",
    "                snips += 1\n",
    "            else:\n",
    "                i.isLeaf = False\n",
    "    print 'Made %d snips' % snips\n",
    "    return tree, least_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    '''\n",
    "    Return number of nodes in the tree\n",
    "    '''\n",
    "    if tree.isLeaf:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree.leftChild) + count_nodes(tree.rightChild)\n",
    "\n",
    "def classify(tree, x, annotate=False):\n",
    "    '''\n",
    "    Returns prediction for a row\n",
    "    '''\n",
    "    # if the node is a leaf node.\n",
    "    if tree.isLeaf:\n",
    "        if annotate:\n",
    "            print \"At leaf, predicting %s\" % tree.prediction()\n",
    "        return tree.prediction()\n",
    "    else:\n",
    "        # split on feature.\n",
    "        feature_value = x[tree.splitting_feature]\n",
    "        split_value = tree.split_value\n",
    "        if annotate:\n",
    "            print \"Split on %s = %s\" % (tree.splitting_feature, feature_value)\n",
    "        if feature_value < split_value:\n",
    "            return classify(tree.leftChild, x, annotate)\n",
    "        else:\n",
    "            return classify(tree.rightChild, x, annotate)\n",
    "\n",
    "def evaluate_classification_error(tree, data, annotate=False):\n",
    "    '''\n",
    "    Returns classification error\n",
    "    '''\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction = data.apply(lambda x: classify(tree, x, annotate=annotate))\n",
    "\n",
    "    # Once you've made the predictions, calculate the classification error and return it\n",
    "    return (data['diagnosis'] != prediction).sum() / float(len(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to abhinav14csu009@ncuindia.edu and will expire on August 16, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Abhinav\\AppData\\Local\\Temp\\graphlab_server_1493391665.log.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Abhinav\\Desktop\\DW&M\\Breast-Cancer-Kaggle\\data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Abhinav\\Desktop\\DW&M\\Breast-Cancer-Kaggle\\data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 569 lines in 0.062533 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 569 lines in 0.062533 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of benign tumors              : 0.490384615385\n",
      "Percentage of malignant tumors           : 0.509615384615\n",
      "Total number of tumors in new dataset    : 416\n"
     ]
    }
   ],
   "source": [
    "data = SFrame.read_csv('data.csv', column_type_hints = [str, str] + [float]*30)\n",
    "benign_raw, malign_raw = data[data['diagnosis'] == 'B'], data[data['diagnosis'] == 'M']\n",
    "percentage = len(malign_raw) / float(len(benign_raw))\n",
    "benign = benign_raw.sample(percentage)\n",
    "malign = malign_raw\n",
    "data = benign.append(malign)\n",
    "data = cross_validation.shuffle(data)\n",
    "\n",
    "print \"Percentage of benign tumors              :\", len(benign) / float(len(data))\n",
    "print \"Percentage of malignant tumors           :\", len(malign) / float(len(data))\n",
    "print \"Total number of tumors in new dataset    :\", len(data)\n",
    "train_data, test_data = data.random_split(.8)\n",
    "target = 'diagnosis'\n",
    "features = data.column_names()[2:]\n",
    "\n",
    "# Test function. Should return perimeter_worst and its median\n",
    "# print best_splitting_feature_gain(data, data.column_names()[2:], 'diagnosis', annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-pruned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (416 data points).\n",
      "Split on feature perimeter_worst at 106.700000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (208 data points).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhinav\\desktop\\dw&m\\gl-env\\lib\\site-packages\\ipykernel_launcher.py:57: RuntimeWarning: divide by zero encountered in log2\n",
      "c:\\users\\abhinav\\desktop\\dw&m\\gl-env\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature perimeter_worst at 86.610000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (104 data points).\n",
      "Split on feature area_se at 18.085000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature radius_worst at 12.230000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature radius_se at 0.310600\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature symmetry_se at 0.024060\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (104 data points).\n",
      "Split on feature perimeter_worst at 96.195000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature texture_worst at 23.130000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature concave points_mean at 0.024880\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature compactness_mean at 0.105800\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature perimeter_worst at 101.650000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature compactness_mean at 0.074015\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature radius_mean at 13.510000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature perimeter_worst at 104.100000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature concave points_worst at 0.102100\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature perimeter_worst at 105.300000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (208 data points).\n",
      "Split on feature perimeter_worst at 139.350000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (104 data points).\n",
      "Split on feature concave points_mean at 0.063810\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature texture_worst at 28.015000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature texture_worst at 22.045000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature texture_worst at 19.140000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature radius_worst at 19.180000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature smoothness_worst at 0.136450\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature symmetry_mean at 0.160900\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature concave points_mean at 0.085040\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature radius_worst at 18.280000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature texture_worst at 30.700000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Less than 10 datapoints left\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (104 data points).\n",
      "Pure node reached\n",
      "Pre-pruned model took 3927.44899988 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create a pre-pruned tree and save that model for later use\n",
    "time_pre = time.time()\n",
    "model_pre_pruned = create_pre_pruned(data, features)\n",
    "print 'Pre-pruned model took {} seconds'.format(time.time() - time_pre)\n",
    "with open('model_pre_pruned.pkl', 'wb') as output:\n",
    "    pkl.dump(model_pre_pruned, output, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbounded tree (Non-pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (416 data points).\n",
      "Split on feature perimeter_worst at 106.700000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (208 data points).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhinav\\desktop\\dw&m\\gl-env\\lib\\site-packages\\ipykernel_launcher.py:57: RuntimeWarning: divide by zero encountered in log2\n",
      "c:\\users\\abhinav\\desktop\\dw&m\\gl-env\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature perimeter_worst at 86.610000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (104 data points).\n",
      "Split on feature area_se at 18.085000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature radius_worst at 12.230000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature radius_se at 0.310600\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature symmetry_se at 0.024060\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Split on feature compactness_mean at 0.071690\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Split on feature compactness_mean at 0.059910\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (104 data points).\n",
      "Split on feature perimeter_worst at 96.195000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature texture_worst at 23.130000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature concave points_mean at 0.024880\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature compactness_mean at 0.105800\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Split on feature texture_mean at 20.890000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Split on feature radius_mean at 12.770000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Split on feature smoothness_mean at 0.108900\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (4 data points).\n",
      "Split on feature smoothness_mean at 0.115350\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Split on feature radius_mean at 11.775000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature perimeter_worst at 101.650000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature compactness_mean at 0.074015\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature radius_mean at 13.510000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Split on feature radius_mean at 12.920000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Split on feature radius_mean at 12.460000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Split on feature radius_mean at 12.670000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature perimeter_worst at 104.100000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature concave points_worst at 0.102100\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Split on feature perimeter_mean at 86.180000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (4 data points).\n",
      "Split on feature texture_mean at 20.655000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature perimeter_worst at 105.300000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Split on feature smoothness_mean at 0.093075\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Split on feature radius_mean at 14.270000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Split on feature radius_mean at 14.620000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Split on feature perimeter_worst at 106.000000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature radius_mean at 13.170000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Split on feature radius_mean at 13.715000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (4 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (208 data points).\n",
      "Split on feature perimeter_worst at 139.350000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (104 data points).\n",
      "Split on feature concave points_mean at 0.063810\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature texture_worst at 28.015000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature texture_worst at 22.045000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature texture_worst at 19.140000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Split on feature concave points_se at 0.010040\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (4 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature radius_worst at 19.180000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Split on feature concave points_mean at 0.053050\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Split on feature texture_mean at 19.100000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature smoothness_worst at 0.136450\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature symmetry_mean at 0.160900\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Split on feature smoothness_mean at 0.088370\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Split on feature texture_mean at 22.110000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Split on feature radius_mean at 15.060000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (4 data points).\n",
      "Split on feature texture_mean at 23.695000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Split on feature radius_mean at 14.040000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (52 data points).\n",
      "Split on feature concave points_mean at 0.085040\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Split on feature radius_worst at 18.280000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Split on feature texture_worst at 30.700000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Split on feature symmetry_mean at 0.179300\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Split on feature radius_mean at 15.370000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3 data points).\n",
      "Split on feature symmetry_mean at 0.211600\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2 data points).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhinav\\desktop\\dw&m\\gl-env\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature radius_mean at 14.020000\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (13 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26 data points).\n",
      "Pure node reached\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (104 data points).\n",
      "Pure node reached\n",
      "Unbounded model took 8111.46399999 seconds\n",
      "Cannot read unbounded model binary file\n"
     ]
    }
   ],
   "source": [
    "# Create an unbounded tree for post-pruning later. Save the model\n",
    "time_unbounded = time.time()\n",
    "model_unbounded = create_unbounded(data, features)\n",
    "print 'Unbounded model took {} seconds'.format(time.time() - time_unbounded)\n",
    "with open('model_unbounded.pkl', 'wb') as output:\n",
    "    pkl.dump(model_unbounded, output, -1)\n",
    "\n",
    "# del model_unbounded\n",
    "try:\n",
    "    with open('model_unbounded.pkl', 'rb') as inp:\n",
    "        tmp = pkl.load(inp)\n",
    "except Exception:\n",
    "    print 'Cannot read unbounded model binary file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune the unbounded tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5fccff88811c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Now prune the unbounded tree and save this too\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtime_post_pruned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_post_pruned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_unbounded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Pruning model took {} seconds'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_post_pruned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_post_pruned.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-bb97ce9e1cb9>\u001b[0m in \u001b[0;36mprune\u001b[1;34m(tree, test_data)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0msnips\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misLeaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Now prune the unbounded tree and save this too\n",
    "time_post_pruned = time.time()\n",
    "model_post_pruned = prune(model_unbounded, test_data)\n",
    "print 'Pruning model took {} seconds'.format(time.time() - time_post_pruned)\n",
    "with open('model_post_pruned.pkl', 'wb') as output:\n",
    "    pkl.dump(model_post_pruned, output, -1)\n",
    "\n",
    "# del model_post_pruned\n",
    "try:\n",
    "    with open('model_post_pruned.pkl', 'rb') as inp:\n",
    "        tmp = pkl.load(inp)\n",
    "except Exception:\n",
    "    print 'Cannot read post pruned model binary file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking our tree for a test drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try classifying some rows from the test_data\n",
    "# Let's look at the first row in the test_data\n",
    "print '----------------Test Data Row----------------------'\n",
    "print test_data[0]\n",
    "print '---------------------------------------------------'\n",
    "# What does the post_pruned model say?\n",
    "print classify(model_post_pruned, test_data[0], annotate=True)\n",
    "# What does the pre_pruned model say?\n",
    "print classify(model_pre_pruned, test_data[0], annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating classification error\n",
    "#### Error here is given by $$\\frac{\\text{total no of records misclassified}}{\\text{total no of records}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # What is the overall classification error?\n",
    "print 'Pre-pruned: %f' % evaluate_classification_error(model_pre_pruned, data)\n",
    "print 'Post-pruned: %f' % evaluate_classification_error(model_post_pruned, data)\n",
    "print 'Unbounded: %f' % evaluate_classification_error(model_unbounded, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
